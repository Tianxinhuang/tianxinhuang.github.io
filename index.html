<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="shortcut icon" href="https://zhishengzhong.com/myIcon.ico">


<meta name="keywords" content="Tianxin Huang, April Lab, Zhejiang University">
<meta name="description" content="Tianxin Huang&#39;s home page">
<!-- <meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs"> -->
<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
<!-- <link rel="icon" type="image/png" href="https://zhishengzhong.com/pic/others/cuhk_logo.png"> -->
<title>Tianxin Huang's Homepage</title>
<!-- Google Analytics -->
<script async="" src="./files/analytics.js"></script><script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/110/three.min.js"></script>

<script type="text/javascript" src="./files/jquery.min.js"></script></head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Tianxin Huang <font face="verdana"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font></h1></div>
				<p>
					School of Computing <br>
					National University of Singapore (NUS) <br>
					<br>
					<br>
					Email 1: <a href="mailto:huangtx@nus.edu.sg">huangtx AT NUS DOT EDU DOT SG</a>
					<br>
					Email 2: <a href="mailto:21725129@zju.edu.cn">21725129 AT zju DOT edu DOT cn</a>

				</p>
				<p>
					<a href="https://scholar.google.com/citations?user=Fg7WYfcAAAAJ&hl=en&oi=ao"><img src="./files/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;
					<!-- <a href="https://github.com/tau-yihouxiang"><img src="./files/github_logo.png" height="30px"></a>&nbsp;&nbsp; -->
				</p>
				<p></p>
			</td>
			<td>
				<img src="./files/selfpic.jpg" border="0" width="150"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography [<a href="./files/huangtx_cv.pdf">CV</a>]</h2>
<!-- <h2>Biography </h2> -->
<p>
	</p><p>
    I am currently a Research Fellow (Postdoc) in National University of Singapore (NUS), School of Computing, in which I am in collaboration with <a href="https://www.comp.nus.edu.sg/~leegh/"> Prof. Gim Hee Lee </a> in 3D Computer Vision.
	Before that, I received the Doctor's Degree at April Lab, <a href="https://www.zju.edu.cn/english/">Zhejiang University (ZJU)</a>, under the supervision of <a href="https://april.zju.edu.cn/team/dr-yong-liu/">Prof. Yong Liu</a>.
        I received the Bachelor degree in Mechanical Engineering from <a href="http://en.xjtu.edu.cn/"> Xi'an Jiaotong University (XJTU)</a> in 2017.

    My current research interests includes but not limited on:
    </p>
    <p>
    <b>3D Point Cloud Geometry Analysis</b>
    </p>
  <p>
  <b>3D Human Face Modeling</b>
  </p>
<p>
<b>3D Scene Understanding and Reconstruction</b>
</p>



<h2>Recent News</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
                        <td>Sep, 2024</td> <td> Three papers (<a href="./projects/Deface">Deface</a>, <a href="https://arxiv.org/pdf/2405.17958">FreeSplat</a>, <a href="https://arxiv.org/pdf/2406.05774">VCR-Gaus</a>) are accepted by NeurIPS 2024! Congratulation to all the co-authors!</td>
                </tr>
		<tr>
                        <td>March, 2024</td> <td> Two papers are accepted by CVPR 2024!</td>
                </tr>
		<tr>
                        <td>June, 2023</td> <td> I join the group led by Gim Hee Lee as a Research Fellow (Postdoc)!</td>
                </tr>
		<tr>
			<td>March, 2023</td> <td> One paper is accepted by CVPR 2023!</td>
		</tr>

<!--		<tr>
			<td>July, 2023</td> <td><a href="https://g3956.github.io">Ref-NeuS</a>: One Oral paper was accepted by ICCV-2023 about 3D Object Reconstruction!</td>
		</tr>
		<tr>
			<td>April, 2023</td> <td><a href="https://realityeditor.com.cn/product-retryon.html">ReTryOn</a>: We released the application of Virtual TryOn within 10 seconds!</td>
		</tr>
		<tr>
			<td>March, 2023</td><td><a href="https://github.com/Reality-Editor/Composition-Stable-Diffusion">RealityComposition</a>: We released the source code of compositing images via Stable Diffusion!</td>
		</tr>
		<tr>
			<td>March, 2023</td> <td><a href="http://cvpr2023.thecvf.com">CVPR-2023</a>: Our three papers were accepted by CVPR-2023! </td>
		</tr> 
-->
	</tbody>
</table>



<h2> Selected Publications [<a href="https://scholar.google.com/citations?user=Fg7WYfcAAAAJ&hl=en&oi=ao">Google Scholar</a>]</h2>
<style>
  table {
    border-collapse: collapse; /* 移除单元格之间的空白 */
  }
  td {
    padding: 5px; /* 调整单元格的内部间距 */
  }
</style>

<table id="tbPublications" width="100%" style="border-collapse:separate; border-spacing:0px 10px;">
	<tbody>
	
	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/deface.png"></td>
                <td>
                        <div><b>Learning to Decouple the Lights for 3D Face Texture Modeling.</b></div>
                        <div style="font-size: 15px"><i> <b>Tianxin Huang</b>, Zhenyu Zhang, Ying Tai, Gim Hee Lee. </i></div>
                        <div>NeurIPS'24</div>
                        <div>[<a href="./projects/Deface"><b>project</b></a>]</div>
                </td>
        </tr>

	
	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/3QNet.png"></td>
		<td>
			<div><b>3QNet: 3D Point Cloud Geometry Quantization Compression Network.</b></div>
			<div style="font-size: 15px"><i> <b>Tianxin Huang</b>, Jiangning Zhang, Jun Chen, Zhonggan Ding, Ying Tai, Zhenyu Zhang, Chengjie Wang, Yong Liu. </i></div>
			<div>Siggraph Asia'22/TOG</div>
			<div>[<a href="./files/3QNet.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/3QNet"><b>Code</b></a>]</div>
		</td>
	</tr>


	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/freesplat.png"></td>
                <td style="font-size: 15px">
                        <div><b>FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes.</b></div>
			<div><i>Yunsong Wang,<b>Tianxin Huang</b>, Hanlin Chen, Gim Hee Lee.</i></div>
                        <div>NeurIPS'24</div>
                        [<a href="https://wangys16.github.io/FreeSplat-project/"><b>Project</b></a>]
                </td>
        </tr>

	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/vcrgaus.png"></td>
                <td style="font-size: 15px">
                        <div><b>VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction.</b></div>
			<div><i>Hanlin Chen, Fangyin Wei, Chen Li,<b> Tianxin Huang</b>, Yunsong Wang, Gim Hee Lee</i></div>
                        <div>NeurIPS'24</div>
                        [<a href="https://hlinchen.github.io/projects/VCR-GauS/"><b>Project</b></a>]
                </td>
        </tr>

	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/Zscom.png"></td>
                <td>
                        <div><b>Zero-shot Point Cloud Completion Via 2D Priors.</b></div>
                        <div style="font-size: 15px"><i> <b>Tianxin Huang</b>, Zhiwen Yan, Yuyang Zhao, Gim Hee Lee. </i></div>
                        <div>Arxiv'24</div>
                        <div>[<a href="https://arxiv.org/abs/2404.06814"><b>paper</b></a>]</div>
                </td>
        </tr>

	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/CALoss.png"></td>
                <td>
                        <div><b>Learning to Measure the Point Cloud Reconstruction Loss in a Representation Space.</b></div>
                        <div style="font-size: 15px"><i><b>Tianxin Huang</b>, Zhonggan Ding, Jiangning Zhang, Ying Tai, Zhenyu Zhang, Mingang Chen, Chengjie Wang, Yong Liu.</i></div>
            <div>CVPR'23</div>
                        <div>[<a href="./files/CALoss.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/CALoss"><b>Code</b></a>]</div>
                </td>
        </tr>

	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/RFNet.png"></td>
                <td>
                        <div><b>RFNet: Recurrent Forward Network for Dense Point Cloud Completion.</b></div>
                        <div style="font-size: 15px"><b>Tianxin Huang</b>, Hao Zou, Jinhao Cui, Xuemeng Yang, Mengmeng Wang, Xiangrui Zhao, Jiangning ZHang, Yi Yuan, Yifan Xu, Yong Liu.</i></div>
            <div>ICCV'21</div>
                        <div>[<a href="./files/RFNet.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/RFNet"><b>Code</b></a>]</div>
                </td>
        </tr>

	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/PCDNet.png"></td>
                <td>
                        <div><b>Resolution-free Point Cloud Sampling Network with Data Distillation.</b></div>
                        <div style="font-size: 15px"><i><b>Tianxin Huang</b>, Jiangning Zhang, Jun Chen, Yuang Liu, Yong Liu.</i></div>
            <div>ECCV'22</div>
                        <div>[<a href="./files/PCDNet.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/PCDNet"><b>Code</b></a>]</div>
                </td>
        </tr>

	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/PCLossNet.png"></td>
		<td>
			<div><b>Learning to Train a Point Cloud Reconstruction Network without Matching.</b></div>
			<div style="font-size: 15px"><i><b>Tianxin Huang</b>, Xuemeng Yang, Jiangning Zhang, Jinhao Cui, Hao Zou, Jun Chen, Xiangrui Zhao, Yong Liu.</i></div>
            <div>ECCV'22</div>
			<div>[<a href="./files/PCLossNet.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/PCLoss"><b>Code</b></a>]</div>
		</td>
	</tr>


	<!-- Tao Hu, Shu Liu, Yilun Chen, Tianchen Shen, Jiaya Jia, ”EfficientNeRF: Efficient Neural Radiance Fields.” CVPR-2022. -->
<!--
	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/ARFNet.png"></td>
		<td style="font-size: 16px">
			<div><b>Adaptive Recurrent Forward Network for Dense Point Cloud Completion.</b></div>
			<div><i><b>Tianxin Huang</b>, Hao Zou, Jinhao Cui, Jiangning Zhang, Xuemeng Yang, Lin Li, Yong Liu.</i></div>
            <div>IEEE Transaction on Multimedia</div>
			[<a href="./files/ARFNet.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/ARFNet"><b>Code</b></a>]
		</td>
	</tr>

	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/FPS.png"></td>
		<td style="font-size: 16px">
			<div><b>Fast Point Cloud Sampling Network.</b></div>
			<div><i><b>Tianxin Huang</b>, Jun Chen, Jiangning Zhang, Yong Liu, Jie Liang.</i></div>
            <div>Pattern Recognition Letters</div>
			[<a href="./files/FPS.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/FPS"><b>Code</b></a>]
		</td>
	</tr>
	<tr>
                <td><img width="300" style="padding: 20px;" src="./files/LCD.png"></td>
                <td style="font-size: 16px">
                        <div><b>Learnable Chamfer Distance for Point Cloud Reconstruction.</b></div>
                        <div><i><b>Tianxin Huang</b>, Qingyao Liu, Xiangrui Zhao, Jun Chen, Yong Liu.</i></div>
            <div>Pattern Recognition Letters</div>
                        [<a href="./files/LCD.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/LCDNet"><b>Code</b></a>]
                </td>
        </tr>

	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/DRS.png"></td>
		<td style="font-size: 16px">
			<div><b>Deep Residual Surrogate Model.</b></div>
			<div><i><b>Tianxin Huang</b>, Zaisheng Pan, Yong Liu.</i></div>
            <div>INFORMATION SCIENCES</div>
			[<a href="./files/DRS.pdf"><b>paper</b></a>|<a href="https://github.com/Tianxinhuang/DRS"><b>Code</b></a>]
		</td>
	</tr>
-->
	<tr>
		<td><img width="300" style="padding: 20px;" src="./files/3DPCC.png"></td>
		<td style="font-size: 16px">
			<div><b>3D Point Cloud Geometry Compression on Deep Learning.</b></div>
			<div><i><b>Tianxin Huang</b>, Yong Liu.</i></div>
            <div>ACM MM'19 Oral</div>
			[<a href="./files/3DPCC.pdf"><b>paper</b></a>]
		</td>
	</tr>

    </tbody>
</table>


<h2> Experiences</h2>
<ul>

    <table width="100%" align="center" border="0" cellpadding="10">
        <tbody><tr>
          <td width="25%" align="center">
            <img src="./files/Tencent.png" alt="face" width="80%">
          </td>
          <td width="75%" valign="center">
                <strong>Feb. 2022 - Feb. 2023</strong>, <b> Tencent Youtu.,Ltd.</b><br> Internship, worked with: <a href="https://jessezhang92.github.io/">Dr. Zhenyu Zhang</a> and <a href="https://tyshiwo.github.io/">Dr. Ying Tai</a> <br>
          </td>
        </tr>
        </tbody>
    </table>

</ul>


 <!--	<h2> Honors and Awards</h2>
<ul>
	<li>
		Postgraduate Scholarship, CUHK, 2019-2023
    </li>
    <li>
		Won the <span style="color: red; font-weight: bold;">Runner-up prize</span> in the JDD pig face recognition Challenge.
    </li>
    <li>
        National Encouragement Scholarship, Beijing, 2013 and 2015
    </li>
</ul>
-->

<h2>Professional Services</h2>

<li>
        <b>Conference Services:</b><br>
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br>
        IEEE International Conference on Computer Vision (ICCV)<br>
        Annual Conference on Neural Information Processing Systems (NeurIPS)<br>
	International Conference on Learning Representations (ICLR)<br>
        Eurographics (EG)<br>
        The British Machine Vision Conference (BMVC)<br>
        International Conference on Intelligent Robots and Systems (IROS)<br>
        ACM SIGGRAPH Asia<br>

        <p style="margin-top:3px"></p>
</li>

<li>
    <b>Journal Reviews:</b><br>
        IEEE Transaction on Multimedia (TMM)<br>
        IEEE Transactions on Intelligent Vehicles (TIV) <br>
        IEEE Transactions on Neural Networks and Learning Systems (TNNLS) <br>
        ACM Transactions on Multimedia Computing Communications and Applications (TOMM) <br>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <br>
        Journal of Field Robotics (JFR)
        <p style="margin-top:3px"></p>          
</li>



<h2>Talking</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2020-2021</td><td>The First International Forum on 3D Optical Sensing and Applications</td><td>3D POINT CLOUD GEOMETRY COMPRESSION BASED ON DEEP LEARNING</td>
		</tr>
		
	</tbody>
</table>

<h1>Where have I been?</h1>
<script>
  // 初始化场景、相机和渲染器
  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
  const renderer = new THREE.WebGLRenderer();
  renderer.setSize(window.innerWidth, window.innerHeight);
  document.body.appendChild(renderer.domElement);

  // 添加地球
  const geometry = new THREE.SphereGeometry(5, 64, 64);
  const texture = new THREE.TextureLoader().load('https://www.solarsystemscope.com/textures/download/2k_earth_daymap.jpg');
  const material = new THREE.MeshBasicMaterial({ map: texture });
  const earth = new THREE.Mesh(geometry, material);
  scene.add(earth);

  // 添加去过地方的红点
  const locations = [
    { lat: 40.7128, lon: -74.0060 }, // 纽约
    { lat: 48.8566, lon: 2.3522 },   // 巴黎
    { lat: 35.6895, lon: 139.6917 }, // 东京
    { lat: -33.8688, lon: 151.2093 } // 悉尼
  ];

  const addMarker = (lat, lon) => {
    const markerGeometry = new THREE.SphereGeometry(0.1, 32, 32);
    const markerMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000 });
    const marker = new THREE.Mesh(markerGeometry, markerMaterial);

    // 将经纬度转换为3D坐标
    const radius = 5; // 地球半径
    const phi = (90 - lat) * (Math.PI / 180); // 纬度转换
    const theta = (lon + 180) * (Math.PI / 180); // 经度转换

    marker.position.set(
      radius * Math.sin(phi) * Math.cos(theta),
      radius * Math.cos(phi),
      radius * Math.sin(phi) * Math.sin(theta)
    );
    scene.add(marker);
  };

  locations.forEach(loc => addMarker(loc.lat, loc.lon));

  // 调整相机位置
  camera.position.z = 10;

  // 添加旋转动画
  const animate = () => {
    requestAnimationFrame(animate);
    earth.rotation.y += 0.001; // 地球自转
    renderer.render(scene, camera);
  };

  animate();
</script>
  
<div id="footer">
	<div id="footer-text"></div>
</div>    
        © Tianxin Huang | Last updated: Jan 2025
</div>

</body></html>
